
# 🔍 Musinsa Search Engine Pipeline (무신사 검색 엔진 파이프라인)

| 특징 | MySQL (RDBMS) | OpenSearch (NoSQL/검색엔진) |
| :--- | :--- | :--- |
| **주요 목적** | 데이터의 저장, 수정, 삭제, **무결성(정확성)** | **빠른 검색**, 대용량 로그 분석, 시각화 |
| **데이터 구조** | 테이블 (Table), 행/열 | 문서 (JSON Document) |
| **검색 능력** | 정확한 값 찾기에 유리 | **전문 검색(Full-text)**, 유사도 검색, 오타 보정 |
| **속도** | 복잡한 검색 시 느려짐 | 대용량 데이터에서도 매우 빠름 |
| **트랜잭션** | 지원 함 (돈 계산 등에 필수) | 지원 안 함 (데이터가 100% 실시간 일치하지 않을 수 있음) |


특징: 검색어를 입력하자마자 미리 만들어둔 사전을 보고 해당되는 글을 순식간에 가져옵니다. 데이터가 수억 건이어도 검색 속도가 매우 빠릅니다.
## 📖 프로젝트 개요
단순한 데이터 수집(Crawling)을 넘어, 수집된 데이터를 **검색 엔진(OpenSearch)**에 적재하고 분석할 수 있는 **ETL 파이프라인**을 구축하는 프로젝트입니다.
비정형 웹 데이터를 정형화된 스키마로 변환하여 저장하고, 한국어 형태소 분석기를 적용하여 검색 품질을 높이는 데 초점을 맞추었습니다.

### 🎯 목표
- **데이터 신뢰성 확보**: 동적 웹페이지(Dynamic DOM) 환경에서도 안정적으로 데이터를 수집하는 크롤러 구현
- **검색 엔지니어링**: RDB가 아닌 역색인(Inverted Index) 기반의 OpenSearch 도입 및 매핑 설계
- **품질 관리**: `analysis-nori` 플러그인을 활용한 한국어 복합명사 처리 및 데이터 정제

---

## 🏗️ 아키텍처 (Architecture)

```text
[ 무신사 웹사이트 ]
       │
       │ (1. 비동기 수집: Playwright Async)
       ▼
[ 데이터 전처리 (ETL Worker) ] 
       │ - HTML 파싱 (Meta Tag & XPath 활용)
       │ - 데이터 정제 (가격 숫자 변환, 불용어 처리)
       │ - 구조화 (JSON Serialize)
       ▼
[ OpenSearch (Docker Container) ] ◀── [ Nori Analyzer (형태소 분석) ]
       │
       │ (3. 시각화 및 모니터링)
       ▼
[ OpenSearch Dashboards ]

```

---

## 🛠️ 기술 스택 (Tech Stack)

* **Language**: Python 3.10+
* **Data Collection**: `Playwright` (Async/Await 기반의 고성능 브라우저 자동화)
* **Search Engine**: `OpenSearch 2.11` (Docker 기반 구축)
* **Analysis**: `analysis-nori` (한국어 형태소 분석기)
* **Container**: Docker, Docker Compose
* **Visualization**: OpenSearch Dashboards

---

## 🔥 문제 해결 (Troubleshooting & Challenges)

프로젝트 진행 중 발생한 주요 기술적 이슈와 해결 과정입니다.

### 1. 동적 클래스명(Dynamic Class Name) 문제

* **문제상황**: 무신사 상세 페이지의 CSS 클래스명이 `sc-m8pxwf-2`와 같이 랜덤하게 생성되어, 재배포 시 크롤러가 동작하지 않음.
* **해결책**:
1. **Meta Tag 활용**: 변하지 않는 `og:title`, `product:price:amount` 메타 태그를 우선적으로 수집.
2. **XPath Relative Query**: "상호 / 대표자"와 같은 고정된 라벨 텍스트(`dt`)를 찾고, `following-sibling`으로 인접한 값(`dd`)을 찾는 '상대 위치 전략' 적용.



### 2. Strict Mode Violation (선택자 중복 에러)

* **문제상황**: `page.locator("meta[property='og:title']")` 실행 시, 사이트 내에 동일한 태그가 2개 존재하여 Playwright가 안전을 위해 에러(`resolved to 2 elements`)를 발생시키고 중단됨.
* **해결책**:
* `.first` 메소드를 체이닝하여 "중복 시 첫 번째 요소를 신뢰한다"는 명시적 로직 추가.
* 예: `page.locator("...").first.get_attribute("content")`



### 3. OpenSearch 데이터 시각화 이슈

* **문제상황**: 데이터 적재 로그(`Success: 20`)는 확인되었으나, Dashboards(Discover) 화면에서 데이터가 보이지 않음.
* **원인**: 기본 조회 필터가 `Last 15 minutes`로 설정되어 있었으나, 데이터 수집 시점과의 차이 발생.
* **해결책**:
* Index Pattern 생성 시 `created_at` 필드를 Time Filter로 지정.
* 조회 범위를 `Last 24 Hours`로 확장하여 데이터 정합성 확인.



---

## 📂 프로젝트 구조 (Directory Structure)

```bash
├── docker-compose.yml       # OpenSearch & Dashboards 컨테이너 설정
├── init_opensearch.py       # 인덱스 생성 및 Mapping(스키마) 정의, Nori 설정
├── v3.0_musinsa_loader.py   # 메인 크롤러 & Bulk Insert 로직
├── musinsa_padding_info.csv # (Legacy) 초기 CSV 저장 버전
└── README.md                # 프로젝트 문서

```

---

## 🚀 실행 방법 (How to Run)

**1. 환경 설정 (Docker)**

```bash
# OpenSearch 컨테이너 실행
docker-compose up -d

# 한국어 분석기 플러그인 설치 (최초 1회)
docker exec -it opensearch-node ./bin/opensearch-plugin install analysis-nori
docker-compose restart

```

**2. 인덱스 초기화**

```bash
# 기존 인덱스 삭제 및 Mapping 적용된 새 인덱스 생성
python init_opensearch.py

```

**3. 데이터 수집 및 적재**

```bash
python v3.0_musinsa_loader.py

```

**4. 결과 확인**

* 브라우저에서 `http://localhost:5601` 접속
* Discover 메뉴에서 데이터 확인

---

## 📅 향후 계획 (Next Steps)

* **FastAPI 백엔드 구축**: 적재된 데이터를 조회하는 REST API 서버 개발
* **복합 쿼리 구현**: 키워드 검색 + 가격 범위 필터링 + 정렬 기능 구현
* **Airflow 도입**: 주기적 자동 수집을 위한 스케줄링 파이프라인 구축


***


